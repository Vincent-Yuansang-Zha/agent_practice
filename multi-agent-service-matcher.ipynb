{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Agent Service Matcher\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates a **simple multi-agent system** that matches a user's free-text request to the best service from a small list of offerings. The system uses **three core agentic concepts**:\n",
    "\n",
    "1. **Multi-Agent Pipeline** - A sequential chain of three specialized LLM-powered agents\n",
    "2. **Custom Tool** - A function that provides data to agents\n",
    "3. **In-Memory Session State** - A mechanism for agents to share context and pass information forward\n",
    "\n",
    "---\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- âœ… How to design a **sequential multi-agent pipeline** where each agent has a specific role\n",
    "- âœ… How to implement **custom tools** that agents can use to access data\n",
    "- âœ… How to manage **session state** so agents can communicate and build on each other's work\n",
    "- âœ… How to use **natural language reasoning** for matching instead of keywords or embeddings\n",
    "- âœ… How to structure prompts for different agent roles\n",
    "\n",
    "---\n",
    "\n",
    "## System Architecture\n",
    "\n",
    "```\n",
    "User Request\n",
    "     |\n",
    "     v\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  AGENT 1: INTERPRETER   â”‚  Role: Clarify and normalize the user's request\n",
    "â”‚  Input: Raw user text   â”‚\n",
    "â”‚  Output: Clear summary  â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "           â”‚ (writes to session)\n",
    "           v\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  AGENT 2: MATCHER       â”‚  Role: Find the best matching service\n",
    "â”‚  Input: Summary + Tool  â”‚  Tool: get_services() â†’ returns service list\n",
    "â”‚  Output: Best match     â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "           â”‚ (writes to session)\n",
    "           v\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  AGENT 3: POLISHER      â”‚  Role: Format user-friendly final answer\n",
    "â”‚  Input: Matched service â”‚\n",
    "â”‚  Output: Final response â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "           â”‚\n",
    "           v\n",
    "    Final Answer\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Why This Architecture?\n",
    "\n",
    "**Separation of Concerns**: Each agent has ONE job, making the system:\n",
    "- Easier to debug (you can inspect each step)\n",
    "- More maintainable (you can improve one agent without touching others)\n",
    "- More testable (you can test each agent independently)\n",
    "\n",
    "**Sequential Pipeline**: Information flows in one direction, making it:\n",
    "- Simple to understand and reason about\n",
    "- Predictable in execution\n",
    "- Easy to extend (just add more agents to the chain)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation\n",
    "\n",
    "We'll use **Google Vertex AI** for our LLM calls. Vertex AI is Google Cloud's enterprise AI platform that provides access to Gemini models through a managed service.\n",
    "\n",
    "### Why Vertex AI?\n",
    "- Enterprise-grade security and reliability\n",
    "- Integrated with Google Cloud Project\n",
    "- No separate API key needed (uses your Google Cloud credentials)\n",
    "- Better for production use cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies are managed via requirements.txt\n",
    "# Install them once in your terminal before running this notebook:\n",
    "#   pip install -r requirements.txt\n",
    "#\n",
    "# If running in Google Colab, uncomment the line below:\n",
    "# !pip install -q google-cloud-aiplatform python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ðŸ”§ Google GenAI Configuration\n",
      "============================================================\n",
      "Project ID: d-ulti-ml-ds-dev-9561\n",
      "Location: us-central1\n",
      "\n",
      "Testing connection...\n",
      "âœ… Google GenAI initialized successfully!\n",
      "âœ… Model response: Ready!\n",
      "\n",
      "Ready to use Gemini models via Vertex AI\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from typing import Dict, List, Any\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get configuration from environment variables\n",
    "PROJECT_ID = os.getenv(\"GOOGLE_CLOUD_PROJECT\")\n",
    "LOCATION = os.getenv(\"GOOGLE_CLOUD_LOCATION\", \"us-central1\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ðŸ”§ Google GenAI Configuration\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Project ID: {PROJECT_ID}\")\n",
    "print(f\"Location: {LOCATION}\")\n",
    "print()\n",
    "\n",
    "try:\n",
    "    # Initialize Google GenAI client with Vertex AI\n",
    "    client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)\n",
    "    \n",
    "    # Test with a simple query to verify it works\n",
    "    print(\"Testing connection...\")\n",
    "    test_response = client.models.generate_content(\n",
    "        model='gemini-2.0-flash-exp',\n",
    "        contents=\"Say 'Ready!' if you can read this\"\n",
    "    )\n",
    "    print(f\"âœ… Google GenAI initialized successfully!\")\n",
    "    print(f\"âœ… Model response: {test_response.text.strip()}\")\n",
    "    print()\n",
    "    print(\"Ready to use Gemini models via Vertex AI\")\n",
    "except Exception as e:\n",
    "    print(\"âŒ Failed to initialize Google GenAI\")\n",
    "    print(f\"Error: {e}\")\n",
    "    print()\n",
    "    print(\"Please ensure:\")\n",
    "    print(\"  1. You've run: gcloud auth application-default login\")\n",
    "    print(\"  2. Your project has Vertex AI API enabled\")\n",
    "    print(\"  3. You have the correct permissions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Custom Tool: Service Database\n",
    "\n",
    "### What is a Custom Tool?\n",
    "\n",
    "In agentic systems, a **tool** is a function that an agent can call to:\n",
    "- Access external data (databases, APIs, files)\n",
    "- Perform calculations or transformations\n",
    "- Execute actions (send emails, update records)\n",
    "\n",
    "**Why use tools?**\n",
    "- LLMs can't access real-time data on their own\n",
    "- Tools extend what agents can do beyond text generation\n",
    "- Tools provide structured, reliable data (unlike asking an LLM to \"remember\" information)\n",
    "\n",
    "### Our Tool: `get_services()`\n",
    "\n",
    "This simple tool returns a hardcoded list of services. In a real application, this might:\n",
    "- Query a database\n",
    "- Call an API\n",
    "- Load from a file\n",
    "\n",
    "For learning purposes, we keep it simple with in-memory data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ Testing get_services() tool:\n",
      "\n",
      "  [1] Python Debug Helper\n",
      "      â†’ I help fix Python bugs quickly using simple explanations.\n",
      "\n",
      "  [2] Tax Filing Advisor\n",
      "      â†’ I answer questions about government tax forms and common filing issues.\n",
      "\n",
      "  [3] Swimming Technique Review\n",
      "      â†’ I give fast feedback on stroke mechanics, breathing, and body position.\n",
      "\n",
      "  [4] SAT Math Tutor\n",
      "      â†’ I explain SAT math problems step-by-step and help improve accuracy.\n",
      "\n",
      "âœ“ Tool returns 4 services\n"
     ]
    }
   ],
   "source": [
    "def get_services() -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Custom tool that returns the list of available services.\n",
    "    \n",
    "    This is a TOOL because:\n",
    "    - It provides data that agents need but don't have\n",
    "    - It's a reusable function that could be called by any agent\n",
    "    - It separates data from logic (agents focus on reasoning, tools provide data)\n",
    "    \n",
    "    Returns:\n",
    "        List of service dictionaries, each containing:\n",
    "        - service_id: Unique identifier\n",
    "        - service_title: Name of the service\n",
    "        - service_description: What the service does\n",
    "    \"\"\"\n",
    "    \n",
    "    # Hardcoded service database\n",
    "    # In a real system, this might come from:\n",
    "    # - A SQL database: SELECT * FROM services\n",
    "    # - A REST API: requests.get(\"https://api.example.com/services\")\n",
    "    # - A JSON file: json.load(open(\"services.json\"))\n",
    "    \n",
    "    services = [\n",
    "        {\n",
    "            \"service_id\": 1,\n",
    "            \"service_title\": \"Python Debug Helper\",\n",
    "            \"service_description\": \"I help fix Python bugs quickly using simple explanations.\"\n",
    "        },\n",
    "        {\n",
    "            \"service_id\": 2,\n",
    "            \"service_title\": \"Tax Filing Advisor\",\n",
    "            \"service_description\": \"I answer questions about government tax forms and common filing issues.\"\n",
    "        },\n",
    "        {\n",
    "            \"service_id\": 3,\n",
    "            \"service_title\": \"Swimming Technique Review\",\n",
    "            \"service_description\": \"I give fast feedback on stroke mechanics, breathing, and body position.\"\n",
    "        },\n",
    "        {\n",
    "            \"service_id\": 4,\n",
    "            \"service_title\": \"SAT Math Tutor\",\n",
    "            \"service_description\": \"I explain SAT math problems step-by-step and help improve accuracy.\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    return services\n",
    "\n",
    "\n",
    "# Test the tool\n",
    "print(\"ðŸ”§ Testing get_services() tool:\\n\")\n",
    "services = get_services()\n",
    "for service in services:\n",
    "    print(f\"  [{service['service_id']}] {service['service_title']}\")\n",
    "    print(f\"      â†’ {service['service_description']}\")\n",
    "    print()\n",
    "\n",
    "print(f\"âœ“ Tool returns {len(services)} services\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Session State Management\n",
    "\n",
    "### What is Session State?\n",
    "\n",
    "**Session state** is a shared memory space where agents store and retrieve information during a single execution run.\n",
    "\n",
    "**Why do we need it?**\n",
    "- Agents need to **communicate**: Agent 2 needs Agent 1's output\n",
    "- Agents need **context**: Each agent builds on previous work\n",
    "- We need **transparency**: We can inspect what each agent produced\n",
    "\n",
    "### Our Implementation: Python Dictionary\n",
    "\n",
    "We use a simple Python dictionary as our session state:\n",
    "\n",
    "```python\n",
    "session = {\n",
    "    \"user_request\": \"original request\",           # Input from user\n",
    "    \"clarified_request\": \"...\",                   # Agent 1 writes this\n",
    "    \"matched_service\": {...},                      # Agent 2 writes this\n",
    "    \"final_response\": \"...\"                       # Agent 3 writes this\n",
    "}\n",
    "```\n",
    "\n",
    "**Key Principle**: Each agent:\n",
    "1. Reads what it needs from the session\n",
    "2. Does its work (usually an LLM call)\n",
    "3. Writes its output back to the session\n",
    "4. Returns the session for the next agent\n",
    "\n",
    "This creates a \"pipeline\" where information flows forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "  Example: Fresh Session\n",
      "============================================================\n",
      "\n",
      "user_request:\n",
      "  I need help with my Python code\n",
      "\n",
      "clarified_request:\n",
      "  None\n",
      "\n",
      "matched_service:\n",
      "  None\n",
      "\n",
      "final_response:\n",
      "  None\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def create_session(user_request: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Initialize a new session with the user's request.\n",
    "    \n",
    "    The session is a dictionary that will be passed through the pipeline.\n",
    "    Each agent will read from it and write to it.\n",
    "    \n",
    "    Args:\n",
    "        user_request: The raw text from the user\n",
    "        \n",
    "    Returns:\n",
    "        A new session dictionary with the user_request as the starting point\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"user_request\": user_request,      # What the user originally asked for\n",
    "        \"clarified_request\": None,          # Agent 1 will fill this\n",
    "        \"matched_service\": None,            # Agent 2 will fill this\n",
    "        \"final_response\": None              # Agent 3 will fill this\n",
    "    }\n",
    "\n",
    "\n",
    "def print_session_state(session: Dict[str, Any], title: str = \"Session State\"):\n",
    "    \"\"\"\n",
    "    Helper function to inspect the current session state.\n",
    "    Useful for debugging and learning how data flows through the pipeline.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"  {title}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    for key, value in session.items():\n",
    "        print(f\"\\n{key}:\")\n",
    "        if isinstance(value, dict):\n",
    "            print(json.dumps(value, indent=2))\n",
    "        else:\n",
    "            print(f\"  {value}\")\n",
    "    print(f\"\\n{'='*60}\\n\")\n",
    "\n",
    "\n",
    "# Test session creation\n",
    "test_session = create_session(\"I need help with my Python code\")\n",
    "print_session_state(test_session, \"Example: Fresh Session\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Agent 1: The Interpreter\n",
    "\n",
    "### Role\n",
    "The Interpreter takes messy, informal user input and transforms it into a clear, normalized summary.\n",
    "\n",
    "### Why is this important?\n",
    "- Users write casually: \"my kid needs help w/ sat math probs\" \n",
    "- Later agents work better with clean input: \"User needs SAT math tutoring\"\n",
    "- It removes noise and focuses on the core need\n",
    "\n",
    "### How it works\n",
    "1. Read `user_request` from session\n",
    "2. Send it to the LLM with a specific prompt\n",
    "3. Store the LLM's clarified version in `clarified_request`\n",
    "4. Return the updated session\n",
    "\n",
    "### Prompt Engineering Note\n",
    "The prompt tells the LLM:\n",
    "- Its role (\"You are an interpreter\")\n",
    "- What to do (\"rewrite into a clear summary\")\n",
    "- Constraints (\"one or two sentences\", \"don't add information\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Testing Agent 1: Interpreter\n",
      "============================================================\n",
      "\n",
      "ðŸ¤– AGENT 1: INTERPRETER is working...\n",
      "   Reading user request: 'my python loop keeps skipping stuff idk why'\n",
      "   âœ“ Clarified to: 'I need help understanding why my Python loop is skipping iterations.'\n",
      "\n",
      "Result:\n",
      "  Original: my python loop keeps skipping stuff idk why\n",
      "  Clarified: I need help understanding why my Python loop is skipping iterations.\n"
     ]
    }
   ],
   "source": [
    "def agent_1_interpreter(session: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    AGENT 1: INTERPRETER\n",
    "    \n",
    "    Clarifies and normalizes the user's raw request into a clean summary.\n",
    "    \n",
    "    Input (from session):\n",
    "        - user_request: Raw text from the user\n",
    "        \n",
    "    Output (written to session):\n",
    "        - clarified_request: A clear, normalized summary of what the user needs\n",
    "        \n",
    "    Returns:\n",
    "        Updated session dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nðŸ¤– AGENT 1: INTERPRETER is working...\")\n",
    "    \n",
    "    # Step 1: Read input from session\n",
    "    user_request = session[\"user_request\"]\n",
    "    print(f\"   Reading user request: '{user_request}'\")\n",
    "    \n",
    "    # Step 2: Prepare the prompt for the LLM\n",
    "    # This is where we define the agent's \"personality\" and task\n",
    "    prompt = f\"\"\"\n",
    "You are an interpreter agent. Your job is to take a user's informal, possibly messy request and rewrite it into a clear, concise summary.\n",
    "\n",
    "Rules:\n",
    "1. Keep it to one or two sentences\n",
    "2. Focus on the main need or problem\n",
    "3. Remove filler words and casual language\n",
    "4. Don't add information that wasn't in the original request\n",
    "5. Don't try to solve the problem - just clarify what they're asking for\n",
    "\n",
    "User request: \"{user_request}\"\n",
    "\n",
    "Provide only the clarified summary, nothing else.\n",
    "\"\"\"\n",
    "    \n",
    "    # Step 3: Call the LLM using Google GenAI\n",
    "    response = client.models.generate_content(\n",
    "        model='gemini-2.0-flash-exp',\n",
    "        contents=prompt\n",
    "    )\n",
    "    clarified_request = response.text.strip()\n",
    "    \n",
    "    print(f\"   âœ“ Clarified to: '{clarified_request}'\")\n",
    "    \n",
    "    # Step 4: Write output to session\n",
    "    session[\"clarified_request\"] = clarified_request\n",
    "    \n",
    "    # Step 5: Return the updated session for the next agent\n",
    "    return session\n",
    "\n",
    "\n",
    "# Test Agent 1 in isolation\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Testing Agent 1: Interpreter\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_session = create_session(\"my python loop keeps skipping stuff idk why\")\n",
    "test_session = agent_1_interpreter(test_session)\n",
    "\n",
    "print(\"\\nResult:\")\n",
    "print(f\"  Original: {test_session['user_request']}\")\n",
    "print(f\"  Clarified: {test_session['clarified_request']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Agent 2: The Matcher\n",
    "\n",
    "### Role\n",
    "The Matcher finds the best service for the user's clarified request using natural language reasoning.\n",
    "\n",
    "### Why is this the hardest agent?\n",
    "- It must **use the tool** (call `get_services()`) to get data\n",
    "- It must **reason** about which service best matches the request\n",
    "- It must **explain** its choice\n",
    "- It must return **structured data** (JSON) that the next agent can use\n",
    "\n",
    "### How it works\n",
    "1. Read `clarified_request` from session\n",
    "2. Call the `get_services()` tool to get the list of services\n",
    "3. Send both the request and service list to the LLM\n",
    "4. Ask the LLM to pick the best match and explain why\n",
    "5. Parse the LLM's response as JSON\n",
    "6. Store the matched service in `matched_service`\n",
    "7. Return the updated session\n",
    "\n",
    "### Key Learning: Tool Integration\n",
    "Notice how we:\n",
    "1. Call the tool ourselves (not the LLM)\n",
    "2. Include the tool's output in the prompt\n",
    "3. Let the LLM reason over the data\n",
    "\n",
    "This is **tool-augmented generation**: we give the LLM real data to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Testing Agent 2: Matcher\n",
      "============================================================\n",
      "\n",
      "ðŸ¤– AGENT 2: MATCHER is working...\n",
      "   Reading clarified request: 'User needs help debugging Python for-loops'\n",
      "   Calling get_services() tool...\n",
      "   âœ“ Retrieved 4 services\n",
      "   âœ“ Matched to: Python Debug Helper\n",
      "   Reason: The user needs help debugging Python code, specifically for-loops, and the Python Debug Helper service is designed to help fix Python bugs.\n",
      "\n",
      "Result:\n",
      "{\n",
      "  \"service_id\": 1,\n",
      "  \"service_title\": \"Python Debug Helper\",\n",
      "  \"service_description\": \"I help fix Python bugs quickly using simple explanations.\",\n",
      "  \"reason\": \"The user needs help debugging Python code, specifically for-loops, and the Python Debug Helper service is designed to help fix Python bugs.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def agent_2_matcher(session: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    AGENT 2: MATCHER\n",
    "    \n",
    "    Finds the best matching service by:\n",
    "    1. Calling the get_services() tool\n",
    "    2. Using LLM reasoning to compare the user's need against each service\n",
    "    3. Selecting the single best match\n",
    "    4. Explaining why it's the best match\n",
    "    \n",
    "    Input (from session):\n",
    "        - clarified_request: The normalized user request from Agent 1\n",
    "        \n",
    "    Output (written to session):\n",
    "        - matched_service: Dictionary containing:\n",
    "            - service_id, service_title, service_description\n",
    "            - reason: Why this service was chosen\n",
    "        \n",
    "    Returns:\n",
    "        Updated session dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nðŸ¤– AGENT 2: MATCHER is working...\")\n",
    "    \n",
    "    # Step 1: Read input from session\n",
    "    clarified_request = session[\"clarified_request\"]\n",
    "    print(f\"   Reading clarified request: '{clarified_request}'\")\n",
    "    \n",
    "    # Step 2: Call the custom tool to get services\n",
    "    # This is the key \"tool use\" concept - agents can call functions to get data\n",
    "    print(\"   Calling get_services() tool...\")\n",
    "    services = get_services()\n",
    "    print(f\"   âœ“ Retrieved {len(services)} services\")\n",
    "    \n",
    "    # Step 3: Format services for the LLM\n",
    "    # We convert the list of services into a readable format\n",
    "    services_text = \"\\n\".join([\n",
    "        f\"Service {s['service_id']}: {s['service_title']}\\n  Description: {s['service_description']}\"\n",
    "        for s in services\n",
    "    ])\n",
    "    \n",
    "    # Step 4: Prepare the prompt\n",
    "    # Notice how we provide both the user's need AND the service list\n",
    "    prompt = f\"\"\"\n",
    "You are a matcher agent. Your job is to find the single best matching service for a user's request.\n",
    "\n",
    "User's need: \"{clarified_request}\"\n",
    "\n",
    "Available services:\n",
    "{services_text}\n",
    "\n",
    "Instructions:\n",
    "1. Read the user's need carefully\n",
    "2. Compare it against each service's title and description\n",
    "3. Use reasoning to determine which service is the BEST match\n",
    "4. Provide a short explanation of WHY this service matches best\n",
    "\n",
    "Return your answer as JSON with this exact structure:\n",
    "{{\n",
    "  \"service_id\": <number>,\n",
    "  \"service_title\": \"<exact title>\",\n",
    "  \"service_description\": \"<exact description>\",\n",
    "  \"reason\": \"<your explanation of why this is the best match>\"\n",
    "}}\n",
    "\n",
    "Return ONLY the JSON, no other text.\n",
    "\"\"\"\n",
    "    \n",
    "    # Step 5: Call the LLM using Google GenAI\n",
    "    response = client.models.generate_content(\n",
    "        model='gemini-2.0-flash-exp',\n",
    "        contents=prompt\n",
    "    )\n",
    "    \n",
    "    # Extract JSON from response (sometimes LLMs add markdown code blocks)\n",
    "    response_text = response.text.strip()\n",
    "    if response_text.startswith(\"```\"):\n",
    "        # Remove markdown code blocks if present\n",
    "        response_text = response_text.split(\"```\")[1]\n",
    "        if response_text.startswith(\"json\"):\n",
    "            response_text = response_text[4:]\n",
    "    matched_service = json.loads(response_text.strip())\n",
    "    \n",
    "    print(f\"   âœ“ Matched to: {matched_service['service_title']}\")\n",
    "    print(f\"   Reason: {matched_service['reason']}\")\n",
    "    \n",
    "    # Step 6: Write output to session\n",
    "    session[\"matched_service\"] = matched_service\n",
    "    \n",
    "    # Step 7: Return the updated session\n",
    "    return session\n",
    "\n",
    "\n",
    "# Test Agent 2 in isolation\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Testing Agent 2: Matcher\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_session = create_session(\"I need help with Python loops\")\n",
    "test_session[\"clarified_request\"] = \"User needs help debugging Python for-loops\"\n",
    "test_session = agent_2_matcher(test_session)\n",
    "\n",
    "print(\"\\nResult:\")\n",
    "print(json.dumps(test_session[\"matched_service\"], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Agent 3: The Polisher\n",
    "\n",
    "### Role\n",
    "The Polisher takes the matched service and creates a polished, user-friendly final response.\n",
    "\n",
    "### Why do we need this agent?\n",
    "- Agent 2 returns structured data (JSON) - not user-friendly\n",
    "- We want a natural, conversational final answer\n",
    "- This separates \"finding the match\" from \"presenting the match\"\n",
    "\n",
    "### How it works\n",
    "1. Read `matched_service` from session\n",
    "2. Send it to the LLM with formatting instructions\n",
    "3. Store the formatted response in `final_response`\n",
    "4. Return the updated session\n",
    "\n",
    "### Design Principle: Single Responsibility\n",
    "Notice how each agent does ONE thing:\n",
    "- Agent 1: Clarify\n",
    "- Agent 2: Match\n",
    "- Agent 3: Format\n",
    "\n",
    "We could combine these, but keeping them separate makes the system:\n",
    "- Easier to modify (change formatting without touching matching logic)\n",
    "- Easier to debug (see exactly where things go wrong)\n",
    "- More reusable (swap out any agent without affecting others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Testing Agent 3: Polisher\n",
      "============================================================\n",
      "\n",
      "ðŸ¤– AGENT 3: POLISHER is working...\n",
      "   Reading matched service: SAT Math Tutor\n",
      "   âœ“ Final response created\n",
      "\n",
      "Result:\n",
      "Best Match: SAT Math Tutor\n",
      "Description: I explain SAT math problems step-by-step and help improve accuracy.\n",
      "Why: I saw you mentioned SAT math word problems, and that's exactly what this tutor specializes in! They can help you break down those problems and boost your confidence.\n"
     ]
    }
   ],
   "source": [
    "def agent_3_polisher(session: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    AGENT 3: POLISHER\n",
    "    \n",
    "    Creates a user-friendly final response from the matched service.\n",
    "    \n",
    "    Input (from session):\n",
    "        - matched_service: The service selected by Agent 2, with reason\n",
    "        \n",
    "    Output (written to session):\n",
    "        - final_response: A polished, conversational answer for the user\n",
    "        \n",
    "    Returns:\n",
    "        Updated session dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nðŸ¤– AGENT 3: POLISHER is working...\")\n",
    "    \n",
    "    # Step 1: Read input from session\n",
    "    matched_service = session[\"matched_service\"]\n",
    "    print(f\"   Reading matched service: {matched_service['service_title']}\")\n",
    "    \n",
    "    # Step 2: Prepare the prompt\n",
    "    # We give the LLM the matched service data and ask for clean formatting\n",
    "    prompt = f\"\"\"\n",
    "You are a polisher agent. Your job is to create a friendly, clear final response for the user.\n",
    "\n",
    "You have matched the user to this service:\n",
    "- Title: {matched_service['service_title']}\n",
    "- Description: {matched_service['service_description']}\n",
    "- Reason for match: {matched_service['reason']}\n",
    "\n",
    "Create a response with this structure:\n",
    "\n",
    "Best Match: [service title]\n",
    "Description: [service description]\n",
    "Why: [explain why this service matches the user's need]\n",
    "\n",
    "Keep it concise and friendly. The \"Why\" should be conversational and clear.\n",
    "\"\"\"\n",
    "    \n",
    "    # Step 3: Call the LLM using Google GenAI\n",
    "    response = client.models.generate_content(\n",
    "        model='gemini-2.0-flash-exp',\n",
    "        contents=prompt\n",
    "    )\n",
    "    final_response = response.text.strip()\n",
    "    \n",
    "    print(\"   âœ“ Final response created\")\n",
    "    \n",
    "    # Step 4: Write output to session\n",
    "    session[\"final_response\"] = final_response\n",
    "    \n",
    "    # Step 5: Return the updated session\n",
    "    return session\n",
    "\n",
    "\n",
    "# Test Agent 3 in isolation\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Testing Agent 3: Polisher\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_session = create_session(\"test\")\n",
    "test_session[\"matched_service\"] = {\n",
    "    \"service_id\": 4,\n",
    "    \"service_title\": \"SAT Math Tutor\",\n",
    "    \"service_description\": \"I explain SAT math problems step-by-step and help improve accuracy.\",\n",
    "    \"reason\": \"The request mentions SAT math word problems, which directly aligns with this service.\"\n",
    "}\n",
    "test_session = agent_3_polisher(test_session)\n",
    "\n",
    "print(\"\\nResult:\")\n",
    "print(test_session[\"final_response\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Pipeline Orchestration\n",
    "\n",
    "### What is a Pipeline?\n",
    "\n",
    "A **pipeline** is a sequence of operations where:\n",
    "- Each operation receives input\n",
    "- Each operation produces output\n",
    "- The output of one operation becomes the input of the next\n",
    "\n",
    "Think of it like an assembly line in a factory:\n",
    "```\n",
    "Raw materials â†’ Station 1 â†’ Station 2 â†’ Station 3 â†’ Finished product\n",
    "```\n",
    "\n",
    "Our pipeline:\n",
    "```\n",
    "User request â†’ Interpreter â†’ Matcher â†’ Polisher â†’ Final response\n",
    "```\n",
    "\n",
    "### Pipeline Pattern Benefits\n",
    "\n",
    "1. **Sequential execution**: Steps happen in order (no parallelism needed here)\n",
    "2. **Shared state**: The session dictionary flows through each step\n",
    "3. **Composable**: Easy to add/remove/reorder agents\n",
    "4. **Debuggable**: Can inspect session after any step\n",
    "\n",
    "### The `run_pipeline()` Function\n",
    "\n",
    "This is the orchestrator. It:\n",
    "1. Creates a fresh session\n",
    "2. Calls each agent in sequence\n",
    "3. Passes the session from one to the next\n",
    "4. Returns the final result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(user_request: str, verbose: bool = True) -> str:\n",
    "    \"\"\"\n",
    "    Orchestrates the multi-agent pipeline.\n",
    "    \n",
    "    This is the main entry point for the entire system. It:\n",
    "    1. Creates a session with the user's request\n",
    "    2. Runs each agent in sequence\n",
    "    3. Returns the final polished response\n",
    "    \n",
    "    Args:\n",
    "        user_request: The raw text from the user\n",
    "        verbose: If True, print detailed progress information\n",
    "        \n",
    "    Returns:\n",
    "        The final formatted response string\n",
    "    \"\"\"\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"ðŸš€ STARTING MULTI-AGENT PIPELINE\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"\\nUser Request: \\\"{user_request}\\\"\\n\")\n",
    "    \n",
    "    # Step 1: Initialize session\n",
    "    # The session is our \"shared memory\" that all agents read from and write to\n",
    "    session = create_session(user_request)\n",
    "    \n",
    "    # Step 2: Run Agent 1 - Interpreter\n",
    "    # Takes messy input, produces clean summary\n",
    "    session = agent_1_interpreter(session)\n",
    "    \n",
    "    # Step 3: Run Agent 2 - Matcher\n",
    "    # Takes clean summary, calls tool, produces matched service\n",
    "    session = agent_2_matcher(session)\n",
    "    \n",
    "    # Step 4: Run Agent 3 - Polisher\n",
    "    # Takes matched service, produces final user-friendly response\n",
    "    session = agent_3_polisher(session)\n",
    "    \n",
    "    # Step 5: Extract and return the final result\n",
    "    final_response = session[\"final_response\"]\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"âœ… PIPELINE COMPLETE\")\n",
    "        print(\"=\"*60)\n",
    "        # Optionally show the full session state for learning purposes\n",
    "        # print_session_state(session, \"Final Session State\")\n",
    "    \n",
    "    return final_response\n",
    "\n",
    "\n",
    "# Helper function to run and display results nicely\n",
    "def match_service(user_request: str):\n",
    "    \"\"\"\n",
    "    Convenience function that runs the pipeline and displays the result.\n",
    "    \"\"\"\n",
    "    result = run_pipeline(user_request, verbose=True)\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ðŸ“‹ FINAL RESPONSE\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\n\" + result + \"\\n\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Example Usage\n",
    "\n",
    "Now let's test the complete system with various user requests!\n",
    "\n",
    "**Note**: The examples below use mock responses. Once you configure your Gemini API key and uncomment the LLM calls in the agent functions, you'll see real AI-powered matching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Python Debugging Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸš€ STARTING MULTI-AGENT PIPELINE\n",
      "============================================================\n",
      "\n",
      "User Request: \"my python code keeps crashing when i try to open a file help!!\"\n",
      "\n",
      "\n",
      "ðŸ¤– AGENT 1: INTERPRETER is working...\n",
      "   Reading user request: 'my python code keeps crashing when i try to open a file help!!'\n",
      "   âœ“ Clarified to: 'My Python code crashes when attempting to open a file, and I need assistance.'\n",
      "\n",
      "ðŸ¤– AGENT 2: MATCHER is working...\n",
      "   Reading clarified request: 'My Python code crashes when attempting to open a file, and I need assistance.'\n",
      "   Calling get_services() tool...\n",
      "   âœ“ Retrieved 4 services\n",
      "   âœ“ Matched to: Python Debug Helper\n",
      "   Reason: The user's problem is a crashing Python code, specifically related to file opening. The Python Debug Helper is designed to fix Python bugs, making it the most relevant service.\n",
      "\n",
      "ðŸ¤– AGENT 3: POLISHER is working...\n",
      "   Reading matched service: Python Debug Helper\n",
      "   âœ“ Final response created\n",
      "\n",
      "============================================================\n",
      "âœ… PIPELINE COMPLETE\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "ðŸ“‹ FINAL RESPONSE\n",
      "============================================================\n",
      "\n",
      "Best Match: Python Debug Helper\n",
      "Description: I help fix Python bugs quickly using simple explanations.\n",
      "Why: Your Python code is crashing when trying to open a file, which definitely sounds like a bug! The Python Debug Helper is here to help you squash that bug and get your code running smoothly. Let's figure out what's going wrong with that file opening!\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Best Match: Python Debug Helper\\nDescription: I help fix Python bugs quickly using simple explanations.\\nWhy: Your Python code is crashing when trying to open a file, which definitely sounds like a bug! The Python Debug Helper is here to help you squash that bug and get your code running smoothly. Let's figure out what's going wrong with that file opening!\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_service(\"my python code keeps crashing when i try to open a file help!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: SAT Math Help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸš€ STARTING MULTI-AGENT PIPELINE\n",
      "============================================================\n",
      "\n",
      "User Request: \"my kid needs help with sat math word problems\"\n",
      "\n",
      "\n",
      "ðŸ¤– AGENT 1: INTERPRETER is working...\n",
      "   Reading user request: 'my kid needs help with sat math word problems'\n",
      "   âœ“ Clarified to: 'My child requires assistance with SAT math word problems.'\n",
      "\n",
      "ðŸ¤– AGENT 2: MATCHER is working...\n",
      "   Reading clarified request: 'My child requires assistance with SAT math word problems.'\n",
      "   Calling get_services() tool...\n",
      "   âœ“ Retrieved 4 services\n",
      "   âœ“ Matched to: SAT Math Tutor\n",
      "   Reason: The user specifically needs help with SAT math word problems, and the SAT Math Tutor service directly addresses this need by offering step-by-step explanations and aiming to improve accuracy in SAT math.\n",
      "\n",
      "ðŸ¤– AGENT 3: POLISHER is working...\n",
      "   Reading matched service: SAT Math Tutor\n",
      "   âœ“ Final response created\n",
      "\n",
      "============================================================\n",
      "âœ… PIPELINE COMPLETE\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "ðŸ“‹ FINAL RESPONSE\n",
      "============================================================\n",
      "\n",
      "Okay, here's the response I've created:\n",
      "\n",
      "Best Match: SAT Math Tutor\n",
      "Description: I explain SAT math problems step-by-step and help improve accuracy.\n",
      "Why: This looks like a great fit! You mentioned needing help with SAT math word problems, and this tutor focuses specifically on that by breaking down problems and helping you get those answers right!\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Okay, here's the response I've created:\\n\\nBest Match: SAT Math Tutor\\nDescription: I explain SAT math problems step-by-step and help improve accuracy.\\nWhy: This looks like a great fit! You mentioned needing help with SAT math word problems, and this tutor focuses specifically on that by breaking down problems and helping you get those answers right!\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_service(\"my kid needs help with sat math word problems\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3: Tax Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸš€ STARTING MULTI-AGENT PIPELINE\n",
      "============================================================\n",
      "\n",
      "User Request: \"i have questions about filing my taxes this year\"\n",
      "\n",
      "\n",
      "ðŸ¤– AGENT 1: INTERPRETER is working...\n",
      "   Reading user request: 'i have questions about filing my taxes this year'\n",
      "   âœ“ Clarified to: 'Clarify questions about this year's tax filing process.'\n",
      "\n",
      "ðŸ¤– AGENT 2: MATCHER is working...\n",
      "   Reading clarified request: 'Clarify questions about this year's tax filing process.'\n",
      "   Calling get_services() tool...\n",
      "   âœ“ Retrieved 4 services\n",
      "   âœ“ Matched to: Tax Filing Advisor\n",
      "   Reason: The user needs help with tax filing questions, and the Tax Filing Advisor service specifically addresses questions about tax forms and filing issues.\n",
      "\n",
      "ðŸ¤– AGENT 3: POLISHER is working...\n",
      "   Reading matched service: Tax Filing Advisor\n",
      "   âœ“ Final response created\n",
      "\n",
      "============================================================\n",
      "âœ… PIPELINE COMPLETE\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "ðŸ“‹ FINAL RESPONSE\n",
      "============================================================\n",
      "\n",
      "Okay, here's the polished response:\n",
      "\n",
      "Best Match: Tax Filing Advisor\n",
      "Description: I answer questions about government tax forms and common filing issues.\n",
      "Why: It sounds like you're looking for help with tax filing, and the Tax Filing Advisor is designed to answer questions about tax forms and any filing issues you might be running into! Let me know what's on your mind!\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Okay, here's the polished response:\\n\\nBest Match: Tax Filing Advisor\\nDescription: I answer questions about government tax forms and common filing issues.\\nWhy: It sounds like you're looking for help with tax filing, and the Tax Filing Advisor is designed to answer questions about tax forms and any filing issues you might be running into! Let me know what's on your mind!\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_service(\"i have questions about filing my taxes this year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4: Swimming Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸš€ STARTING MULTI-AGENT PIPELINE\n",
      "============================================================\n",
      "\n",
      "User Request: \"I want to improve my freestyle stroke breathing\"\n",
      "\n",
      "\n",
      "ðŸ¤– AGENT 1: INTERPRETER is working...\n",
      "   Reading user request: 'I want to improve my freestyle stroke breathing'\n",
      "   âœ“ Clarified to: 'Clarify techniques for freestyle stroke breathing.'\n",
      "\n",
      "ðŸ¤– AGENT 2: MATCHER is working...\n",
      "   Reading clarified request: 'Clarify techniques for freestyle stroke breathing.'\n",
      "   Calling get_services() tool...\n",
      "   âœ“ Retrieved 4 services\n",
      "   âœ“ Matched to: Swimming Technique Review\n",
      "   Reason: The user's request is about freestyle stroke breathing techniques, which directly aligns with the description of the Swimming Technique Review service.\n",
      "\n",
      "ðŸ¤– AGENT 3: POLISHER is working...\n",
      "   Reading matched service: Swimming Technique Review\n",
      "   âœ“ Final response created\n",
      "\n",
      "============================================================\n",
      "âœ… PIPELINE COMPLETE\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "ðŸ“‹ FINAL RESPONSE\n",
      "============================================================\n",
      "\n",
      "Okay, here's a response tailored for the user:\n",
      "\n",
      "Best Match: Swimming Technique Review\n",
      "Description: I give fast feedback on stroke mechanics, breathing, and body position.\n",
      "Why: This service sounds perfect for you! Since you're asking about freestyle stroke breathing techniques, I can give you some quick feedback on that, along with your overall stroke mechanics and body position. Let's get you swimming even better!\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Okay, here's a response tailored for the user:\\n\\nBest Match: Swimming Technique Review\\nDescription: I give fast feedback on stroke mechanics, breathing, and body position.\\nWhy: This service sounds perfect for you! Since you're asking about freestyle stroke breathing techniques, I can give you some quick feedback on that, along with your overall stroke mechanics and body position. Let's get you swimming even better!\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_service(\"I want to improve my freestyle stroke breathing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 5: Edge Case - Ambiguous Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸš€ STARTING MULTI-AGENT PIPELINE\n",
      "============================================================\n",
      "\n",
      "User Request: \"I need help with numbers\"\n",
      "\n",
      "\n",
      "ðŸ¤– AGENT 1: INTERPRETER is working...\n",
      "   Reading user request: 'I need help with numbers'\n",
      "   âœ“ Clarified to: 'The user requires assistance with numerical information.'\n",
      "\n",
      "ðŸ¤– AGENT 2: MATCHER is working...\n",
      "   Reading clarified request: 'The user requires assistance with numerical information.'\n",
      "   Calling get_services() tool...\n",
      "   âœ“ Retrieved 4 services\n",
      "   âœ“ Matched to: SAT Math Tutor\n",
      "   Reason: The user needs assistance with numerical information, and the SAT Math Tutor focuses specifically on explaining and improving accuracy with math problems, making it the best match among the available services.\n",
      "\n",
      "ðŸ¤– AGENT 3: POLISHER is working...\n",
      "   Reading matched service: SAT Math Tutor\n",
      "   âœ“ Final response created\n",
      "\n",
      "============================================================\n",
      "âœ… PIPELINE COMPLETE\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "ðŸ“‹ FINAL RESPONSE\n",
      "============================================================\n",
      "\n",
      "Okay, here's the polished response for the user:\n",
      "\n",
      "Best Match: SAT Math Tutor\n",
      "Description: I explain SAT math problems step-by-step and help improve accuracy.\n",
      "Why: You mentioned needing help with numerical information, and the SAT Math Tutor is all about explaining math problems clearly and helping you get more accurate answers. Seems like a great fit!\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Okay, here's the polished response for the user:\\n\\nBest Match: SAT Math Tutor\\nDescription: I explain SAT math problems step-by-step and help improve accuracy.\\nWhy: You mentioned needing help with numerical information, and the SAT Math Tutor is all about explaining math problems clearly and helping you get more accurate answers. Seems like a great fit!\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This tests how the system handles requests that could match multiple services\n",
    "match_service(\"I need help with numbers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Debugging and Inspection\n",
    "\n",
    "One of the benefits of the pipeline pattern is that you can inspect the session state at any point.\n",
    "\n",
    "This is incredibly valuable for:\n",
    "- **Learning**: See exactly what each agent produces\n",
    "- **Debugging**: Find where things go wrong\n",
    "- **Optimization**: Identify which agent needs improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ” RUNNING PIPELINE WITH INSPECTION\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "  Initial State\n",
      "============================================================\n",
      "\n",
      "user_request:\n",
      "  python loop broken help\n",
      "\n",
      "clarified_request:\n",
      "  None\n",
      "\n",
      "matched_service:\n",
      "  None\n",
      "\n",
      "final_response:\n",
      "  None\n",
      "\n",
      "============================================================\n",
      "\n",
      "\n",
      "ðŸ¤– AGENT 1: INTERPRETER is working...\n",
      "   Reading user request: 'python loop broken help'\n",
      "   âœ“ Clarified to: 'The user needs help debugging a broken loop in their Python code.'\n",
      "\n",
      "============================================================\n",
      "  After Agent 1 (Interpreter)\n",
      "============================================================\n",
      "\n",
      "user_request:\n",
      "  python loop broken help\n",
      "\n",
      "clarified_request:\n",
      "  The user needs help debugging a broken loop in their Python code.\n",
      "\n",
      "matched_service:\n",
      "  None\n",
      "\n",
      "final_response:\n",
      "  None\n",
      "\n",
      "============================================================\n",
      "\n",
      "\n",
      "ðŸ¤– AGENT 2: MATCHER is working...\n",
      "   Reading clarified request: 'The user needs help debugging a broken loop in their Python code.'\n",
      "   Calling get_services() tool...\n",
      "   âœ“ Retrieved 4 services\n",
      "   âœ“ Matched to: Python Debug Helper\n",
      "   Reason: The user specifically needs help debugging Python code, and the Python Debug Helper is designed for that purpose.\n",
      "\n",
      "============================================================\n",
      "  After Agent 2 (Matcher)\n",
      "============================================================\n",
      "\n",
      "user_request:\n",
      "  python loop broken help\n",
      "\n",
      "clarified_request:\n",
      "  The user needs help debugging a broken loop in their Python code.\n",
      "\n",
      "matched_service:\n",
      "{\n",
      "  \"service_id\": 1,\n",
      "  \"service_title\": \"Python Debug Helper\",\n",
      "  \"service_description\": \"I help fix Python bugs quickly using simple explanations.\",\n",
      "  \"reason\": \"The user specifically needs help debugging Python code, and the Python Debug Helper is designed for that purpose.\"\n",
      "}\n",
      "\n",
      "final_response:\n",
      "  None\n",
      "\n",
      "============================================================\n",
      "\n",
      "\n",
      "ðŸ¤– AGENT 3: POLISHER is working...\n",
      "   Reading matched service: Python Debug Helper\n",
      "   âœ“ Final response created\n",
      "\n",
      "============================================================\n",
      "  After Agent 3 (Polisher)\n",
      "============================================================\n",
      "\n",
      "user_request:\n",
      "  python loop broken help\n",
      "\n",
      "clarified_request:\n",
      "  The user needs help debugging a broken loop in their Python code.\n",
      "\n",
      "matched_service:\n",
      "{\n",
      "  \"service_id\": 1,\n",
      "  \"service_title\": \"Python Debug Helper\",\n",
      "  \"service_description\": \"I help fix Python bugs quickly using simple explanations.\",\n",
      "  \"reason\": \"The user specifically needs help debugging Python code, and the Python Debug Helper is designed for that purpose.\"\n",
      "}\n",
      "\n",
      "final_response:\n",
      "  Okay, here's the response:\n",
      "\n",
      "Best Match: Python Debug Helper\n",
      "Description: I help fix Python bugs quickly using simple explanations.\n",
      "Why: You're looking for help debugging your Python code, and that's exactly what I'm designed to do! I'll help you squash those bugs!\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Okay, here's the response:\\n\\nBest Match: Python Debug Helper\\nDescription: I help fix Python bugs quickly using simple explanations.\\nWhy: You're looking for help debugging your Python code, and that's exactly what I'm designed to do! I'll help you squash those bugs!\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run_pipeline_with_inspection(user_request: str):\n",
    "    \"\"\"\n",
    "    Run the pipeline but show session state after each agent.\n",
    "    Useful for learning and debugging.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ðŸ” RUNNING PIPELINE WITH INSPECTION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    session = create_session(user_request)\n",
    "    print_session_state(session, \"Initial State\")\n",
    "    \n",
    "    session = agent_1_interpreter(session)\n",
    "    print_session_state(session, \"After Agent 1 (Interpreter)\")\n",
    "    \n",
    "    session = agent_2_matcher(session)\n",
    "    print_session_state(session, \"After Agent 2 (Matcher)\")\n",
    "    \n",
    "    session = agent_3_polisher(session)\n",
    "    print_session_state(session, \"After Agent 3 (Polisher)\")\n",
    "    \n",
    "    return session[\"final_response\"]\n",
    "\n",
    "# Example: Inspect a request step-by-step\n",
    "run_pipeline_with_inspection(\"python loop broken help\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. Key Takeaways and Learning Summary\n",
    "\n",
    "Congratulations! You've built a complete multi-agent system. Let's review what you learned:\n",
    "\n",
    "### 1. Multi-Agent Systems\n",
    "\n",
    "**What**: Multiple AI agents working together, each with a specific role\n",
    "\n",
    "**Why**: \n",
    "- Separation of concerns (each agent has one job)\n",
    "- Easier to debug and improve\n",
    "- More modular and maintainable\n",
    "\n",
    "**How**: \n",
    "- Define clear roles for each agent\n",
    "- Use prompts to give each agent its \"personality\"\n",
    "- Chain agents in a sequence (pipeline pattern)\n",
    "\n",
    "### 2. Custom Tools\n",
    "\n",
    "**What**: Functions that agents can call to access data or perform actions\n",
    "\n",
    "**Why**: \n",
    "- LLMs can't access external data without tools\n",
    "- Tools provide reliable, structured information\n",
    "- Tools extend what agents can do beyond text generation\n",
    "\n",
    "**How**: \n",
    "- Create simple functions that return data\n",
    "- Call tools in your agent code\n",
    "- Include tool output in prompts for LLM reasoning\n",
    "\n",
    "### 3. Session State Management\n",
    "\n",
    "**What**: A shared memory space where agents store and retrieve information\n",
    "\n",
    "**Why**: \n",
    "- Agents need to communicate\n",
    "- Each agent builds on previous work\n",
    "- Enables sequential processing\n",
    "\n",
    "**How**: \n",
    "- Use a dictionary to store state\n",
    "- Each agent reads from and writes to the session\n",
    "- Pass the session through the pipeline\n",
    "\n",
    "### 4. Pipeline Pattern\n",
    "\n",
    "**What**: A sequence of operations where output flows from one to the next\n",
    "\n",
    "**Why**: \n",
    "- Simple and predictable execution\n",
    "- Easy to reason about\n",
    "- Easy to extend or modify\n",
    "\n",
    "**How**: \n",
    "- Create functions for each stage\n",
    "- Each function takes state, modifies it, returns it\n",
    "- Orchestrate with a main function\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "To deepen your learning, try these exercises:\n",
    "\n",
    "1. **Add a 4th agent**: Create a \"Validator\" that checks if the match quality is high enough\n",
    "   \n",
    "2. **Add more services**: Expand the service list to 10+ items and test edge cases\n",
    "   \n",
    "3. **Add a second tool**: Create `get_user_history()` that returns past requests, and use it in Agent 2\n",
    "   \n",
    "4. **Improve prompts**: Experiment with different prompt styles to improve matching accuracy\n",
    "   \n",
    "5. **Add error handling**: What happens if the LLM returns invalid JSON? Add try/catch blocks\n",
    "   \n",
    "6. **Parallel agents**: Research how to run multiple agents in parallel instead of sequentially\n",
    "   \n",
    "7. **Add confidence scores**: Have Agent 2 return a confidence score (0-100) with each match\n",
    "\n",
    "---\n",
    "\n",
    "## Resources for Further Learning\n",
    "\n",
    "- **LangChain Documentation**: More advanced agent frameworks\n",
    "- **AutoGen**: Microsoft's multi-agent conversation framework  \n",
    "- **CrewAI**: Role-based agent collaboration\n",
    "- **OpenAI Function Calling**: How to let LLMs decide which tools to use\n",
    "\n",
    "---\n",
    "\n",
    "**Remember**: The best way to learn is by building. Take this notebook and modify it. Break it. Fix it. Add features. That's how you truly understand agentic systems!\n",
    "\n",
    "Happy coding! ðŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
